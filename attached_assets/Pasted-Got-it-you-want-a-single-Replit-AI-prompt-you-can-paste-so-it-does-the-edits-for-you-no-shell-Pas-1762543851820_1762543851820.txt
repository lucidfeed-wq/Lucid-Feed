Got it—you want a single Replit AI prompt you can paste so it does the edits for you (no shell). Paste the block below into Replit’s AI (“Help me code” / Ghostwriter) and let it run.

⸻

Replit AI Prompt (paste this whole thing)

Goal: Harden our Reddit client and discovery. Add proper User-Agent headers, token caching, jittered backoff, and support both global search and subreddit listings. Keep existing env secrets. Don’t change any other files.

Make these edits:
	1.	Create/overwrite server/services/feed-discovery/reddit-search.ts with exactly this file content:

/**
 * Hardened Reddit client for LucidFeed
 * - Proper User-Agent on every call (required by Reddit)
 * - OAuth password grant token caching with refresh
 * - Exponential backoff with jitter
 * - Both global search and subreddit listings for robust discovery
 */
import fetch from "node-fetch";

const UA =
  process.env.REDDIT_USER_AGENT ??
  `LucidFeed/1.0 (+https://getlucidfeed.com; contact: admin@getlucidfeed.com) by u/${process.env.REDDIT_USERNAME ?? "lucidbot_123"}`;

const CLIENT_ID = process.env.REDDIT_CLIENT_ID!;
const CLIENT_SECRET = process.env.REDDIT_SECRET!;
const USERNAME = process.env.REDDIT_USERNAME!;
const PASSWORD = process.env.REDDIT_PASSWORD!;

let token: string | null = null;
let tokenExp = 0;

function sleep(ms: number) {
  return new Promise((r) => setTimeout(r, ms));
}

async function withBackoff<T>(fn: () => Promise<T>, tries = 5): Promise<T> {
  let d = 300;
  for (let i = 0; i < tries; i++) {
    try {
      return await fn();
    } catch (e: any) {
      if (i === tries - 1) throw e;
      const jitter = Math.floor(Math.random() * 150);
      const wait = Math.min(d * Math.pow(1.8, i) + jitter, 5000);
      await sleep(wait);
    }
  }
  throw new Error("withBackoff exhausted");
}

async function getToken(): Promise<string> {
  const now = Date.now();
  if (token && now < tokenExp - 60_000) return token;

  const auth = Buffer.from(`${CLIENT_ID}:${CLIENT_SECRET}`).toString("base64");
  const body = new URLSearchParams({
    grant_type: "password",
    username: USERNAME,
    password: PASSWORD,
    scope: "read",
  });

  const r = await fetch("https://www.reddit.com/api/v1/access_token", {
    method: "POST",
    headers: {
      Authorization: `Basic ${auth}`,
      "Content-Type": "application/x-www-form-urlencoded",
      "User-Agent": UA,
    },
    body,
  });

  if (!r.ok) {
    const txt = await r.text();
    throw new Error(`Reddit auth ${r.status}: ${txt}`);
  }
  const j = (await r.json()) as { access_token: string; expires_in: number };
  token = j.access_token;
  tokenExp = Date.now() + j.expires_in * 1000;
  return token!;
}

function headers(t: string) {
  return {
    Authorization: `bearer ${t}`,
    "User-Agent": UA,
    Accept: "application/json",
  };
}

/** Preferred for production discovery: subreddit listings (less filtered than /search) */
export async function redditList(
  subreddit: string,
  type: "new" | "hot" | "top" = "new",
  opts: { limit?: number; t?: "hour" | "day" | "week" | "month" | "year" | "all" } = {}
) {
  const t = await getToken();
  const limit = String(opts.limit ?? 25);
  const tparam = opts.t ? `&t=${opts.t}` : "";
  const url = `https://oauth.reddit.com/r/${encodeURIComponent(subreddit)}/${type}?limit=${limit}${tparam}`;

  return withBackoff(async () => {
    const r = await fetch(url, { headers: headers(t) });
    const ct = r.headers.get("content-type") || "";
    const txt = await r.text();
    if (!r.ok || ct.includes("text/html")) {
      throw new Error(`Reddit listing ${r.status}: ${txt.slice(0, 200)}`);
    }
    return JSON.parse(txt);
  });
}

/** Global search (works now but more likely to be rate-limited/blocked) */
export async function searchRedditSubreddits(query: string) {
  const t = await getToken();
  const url = `https://oauth.reddit.com/search?limit=25&q=${encodeURIComponent(query)}&type=sr`;
  return withBackoff(async () => {
    const r = await fetch(url, { headers: headers(t) });
    const ct = r.headers.get("content-type") || "";
    const txt = await r.text();
    if (!r.ok || ct.includes("text/html")) {
      throw new Error(`Reddit search ${r.status}: ${txt.slice(0, 200)}`);
    }
    const j = JSON.parse(txt);
    const subs = (j?.data?.children ?? []).map((c: any) => c?.data?.display_name).filter(Boolean);
    return subs as string[];
  });
}

/** Combined discovery helper (topic + seed subreddits) */
export async function discoverTopic(topic: string, seedSubs: string[]) {
  const [fromSearch, fromSeeds] = await Promise.allSettled([
    searchRedditSubreddits(topic),
    Promise.all(
      seedSubs.map((s) =>
        redditList(s, "new", { limit: 25 }).then((v) => ({ sub: s, ok: true, v })).catch((e) => ({ sub: s, ok: false, e }))
      )
    ),
  ]);
  return { fromSearch, fromSeeds };
}

	2.	Do not change imports elsewhere. The file still exports:

	•	searchRedditSubreddits
	•	redditList
	•	discoverTopic

	3.	Add an env default for UA (optional, but helpful):

	•	If REDDIT_USER_AGENT exists, use it; otherwise the file already builds a proper UA string from REDDIT_USERNAME.
	•	No Secrets changes required here.

	4.	(Optional) Add a minimal smoke test script at scripts/smoke-reddit.ts (only if the repo uses scripts; skip if it doesn’t). Content:

import { searchRedditSubreddits, redditList } from "../server/services/feed-discovery/reddit-search";

(async () => {
  const subs = await searchRedditSubreddits("carnivore");
  console.log("SEARCH:", subs.slice(0, 10));
  const listing = await redditList("keto", "new", { limit: 5 });
  console.log(
    "LIST FIRST TITLES:",
    (listing?.data?.children ?? []).map((c: any) => c?.data?.title).slice(0, 5)
  );
})();

	5.	Ensure nothing else in the project breaks. If other modules import a different path for reddit discovery, mirror this file there as well instead of changing callers.
	6.	Run the app so it compiles the new TypeScript and starts using the updated client. No further config is needed since secrets are already set.

Acceptance criteria:
	•	Startup logs show a proper UA (either from REDDIT_USER_AGENT or the default string with the current REDDIT_USERNAME).
	•	Discovery works via both /search and /r/<sub>/new.
	•	No more HTML “Blocked” pages surface in logs; if Reddit responds with HTML, our client throws and retries with backoff rather than spamming.

When you’re done, tell me which files were changed and commit the update.