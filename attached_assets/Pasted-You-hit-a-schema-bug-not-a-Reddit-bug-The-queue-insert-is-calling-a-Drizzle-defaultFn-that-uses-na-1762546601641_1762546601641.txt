You hit a schema bug, not a Reddit bug. The queue insert is calling a Drizzle defaultFn that uses nanoid, but nanoid isn’t imported/available in your runtime, so the insert explodes:

❌ Failed to enqueue digest job: ReferenceError: nanoid is not defined
at PgVarchar.defaultFn ...

The fix

Stop generating IDs with nanoid in app code. Use a UUID primary key that Drizzle/DB will generate for you. This removes the dependency and the crash.

Below is a single Replit AI prompt you can paste into Ghostwriter. It:
	•	Changes the digest_jobs table to use uuid with .defaultRandom() (client-side UUID via Drizzle — no DB extensions needed).
	•	Removes any defaultFn: () => nanoid() usage.
	•	Ensures enqueueDigest() doesn’t pass an id.
	•	Leaves your async job, progress, and performance tweaks intact.

⸻

Replit AI Prompt — Fix “nanoid is not defined” and make jobs robust

Goal: Replace nanoid IDs with UUIDs generated by Drizzle so enqueuing digest jobs never throws. Do not change functionality, only the ID strategy.

1) Update Drizzle schema for digest_jobs

Locate your Drizzle schema file that defines digest_jobs (e.g., server/db/schema.ts). Replace that table definition to use uuid with .defaultRandom() and remove any defaultFn/nanoid:

// import these at top of schema file:
import { pgTable, uuid, text, integer, timestamp } from "drizzle-orm/pg-core";

// Replace existing digest_jobs definition with this:
export const digestJobs = pgTable("digest_jobs", {
  id: uuid("id").defaultRandom().primaryKey(),    // ✅ UUID, no nanoid
  createdAt: timestamp("created_at", { withTimezone: true }).defaultNow().notNull(),
  updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow().notNull(),
  topic: text("topic"),
  userId: text("user_id"),
  status: text("status").notNull(),               // ('queued','running','done','error')
  progress: integer("progress").notNull().default(0),
  total: integer("total").notNull().default(0),
  digestId: text("digest_id"),
  error: text("error"),
});

If your project splits columns into objects, still ensure id is uuid().defaultRandom().primaryKey() and no defaultFn(() => nanoid()) remains anywhere.

2) Migration (if you created the table as varchar)

If the table already exists with id as varchar or without default, add a migration to convert it to uuid and set a default. If you prefer to avoid DB-level ALTERs, you can keep the column as uuid in Drizzle and let Drizzle supply the value client-side; just ensure the actual DB column is uuid too.

Minimal “make it work now” approach:
	•	If you can rerun schema creation in dev, drop and recreate digest_jobs (dev only).
	•	If you need a forward migration in prod, apply:

-- Only if the column is currently text/varchar. Backup first if you have live data.
alter table digest_jobs
  alter column id drop default;

-- If it's text, you need a new uuid column and swap; otherwise skip the type change:
-- Example (Postgres):
-- alter table digest_jobs add column id_uuid uuid;
-- update digest_jobs set id_uuid = gen_random_uuid();
-- alter table digest_jobs drop column id;
-- alter table digest_jobs rename column id_uuid to id;
-- alter table digest_jobs alter column id set not null;
-- alter table digest_jobs add primary key (id);

-- Drizzle will now provide defaultRandom() client-side; no DB default required.

(If you already created with uuid in SQL earlier, you can keep it and add a DB default of gen_random_uuid() instead; both are fine. The key point is: no nanoid.)

3) Fix enqueue code so we don’t pass id

Find your queue/enqueue implementation (e.g., server/jobs/digest-queue.ts):

// BEFORE (do not do this)
// await db.insert(digestJobs).values({ id: nanoid(), ... });

// AFTER: let Drizzle/UUID default supply the id
const inserted = await db.insert(digestJobs).values({
  topic,
  userId,
  status: "queued",
}).returning({ id: digestJobs.id });

const jobId = inserted[0].id; // UUID string

Ensure no residual nanoid imports/usages remain anywhere in the project (schema, enqueue, helpers).

4) Status/progress: no change needed

Your existing status route and runner stay the same. They’ll now read/write a UUID id.

5) Clean up dependencies (optional)

If nanoid is in package.json but unused, you can remove it later. Not required.

6) Quick acceptance test
	•	Trigger POST /api/digest/refresh.
	•	Expect: 202 { jobId: "<uuid>" } without a 500.
	•	Logs should show:
	•	[Digest Queue] Enqueuing digest job ... → no error
	•	Runner flips queued → running → done
	•	Your previous Reddit/YouTube logs continue to show discovery working.
	•	Frontend polls /api/digest/status?jobId=... until done.

⸻

Important: Leave all the earlier performance improvements (bounded concurrency, early discard, caching, YouTube RSS ingest, journal-first) as you implemented — this fix is only for the job ID crash.

If you paste this and Ghostwriter can’t find the schema file, tell me your exact schema file path and table definition snippet and I’ll generate a surgical diff for that file.