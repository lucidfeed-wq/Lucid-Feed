Replit Implementation Prompt â€” LucidFeed Scale & API

Goal: Implement a scalable, RSSâ€‘first ingestion + selective enrichment architecture, harden API usage (rate limits, backoff, caching), and ship onboarding + payments + smarter chat per the current plan.

â¸»

ğŸ”§ What to Build (Scope)
	1.	Feed Discovery Service (YouTube/Podcasts/Reddit/Substack/Journals) using RSS for discovery.
	2.	Feed Discovery UI with Search and Onboarding Wizard (firstâ€‘login flow).
	3.	Stripe Subscription Flow with tiers (Free, Premium, Pro) and enforce feature gates.
	4.	Userâ€‘level Digest Generation (weekly/daily) with cached, reusable summaries.
	5.	Enhanced Conversational Chat (twoâ€‘stage: retrieve â†’ summarize/synthesize) + Chat History Persistence.
	6.	Scale & API Safety: BullMQ queues, perâ€‘source concurrency, backoff, caching, canonical merge, and observability.

Prioritize: (A) Feed Discovery Service â†’ (B) Discovery UI + Onboarding â†’ (C) Chat improvements â†’ (D) Stripe + Digests â†’ (E) Ops hardening (queues/metrics).

â¸»

âœ… Acceptance Criteria (Definition of Done)
	â€¢	No hard API dependencies for ingestion (RSSâ€‘first for all sources). Enrichment uses safe, cached calls.
	â€¢	Perâ€‘source concurrency + backoff to avoid 429s; failures donâ€™t cascade. Deadâ€‘letter queue captures persistent failures.
	â€¢	Canonical merge: items deduped by DOI or normalized URL; social posts linked via related_refs.
	â€¢	Onboarding flow: user selects topics â†’ sees curated sources/bundles â†’ oneâ€‘click add â†’ digest created within first session.
	â€¢	Chat can summarize an entire digest with citations to included items; hallucination guardrails enforced.
	â€¢	Stripe plans work endâ€‘toâ€‘end with portal; feature gates respected per tier; token/cost usage tracked per user.
	â€¢	Observability: healthcheck + Sentry + structured logs; PostHog basic funnel events wired.

â¸»

ğŸ§± Architectural Requirements (API & Scale)

1) Ingestion Strategy
	â€¢	Discovery: RSS only for YouTube (channel feeds), Podcasts (PodcastIndex â†’ RSS), Reddit (subreddit RSS), Substack (site RSS), Journals (PubMed/Crossref search results â†’ stored as sources).
	â€¢	Content Fetch:
	â€¢	YouTube transcripts: use youtube-transcript selectively behind a queue (no API key). If captions missing, fallback to description.
	â€¢	Podcasts: RSS description shown; optional transcript only if explicitly available.
	â€¢	Substack/Reddit: consume RSS content; avoid HTML scraping unless necessary.
	â€¢	Journals: PubMed/Crossref/Semantic Scholar for metadata; Unpaywall PDFs where available.

2) Rate Limits & Backoff (Perâ€‘Source Policies)
	â€¢	Global: implement BullMQ queues with perâ€‘source concurrency caps and retry policies:
	â€¢	YouTube transcripts: concurrency 5â€“10, backoff exponential (initial 2s, factor 2, jitter), max retries 5.
	â€¢	RSS pulls: concurrency 50, respect ETag/Last-Modified; min interval per feed 10â€“30 min.
	â€¢	PubMed/Crossref/S2: obey provider guidance;
	â€¢	PubMed: with API key target â‰¤ 10 req/sec; without key â‰¤ 3 req/sec; set tool and email headers.
	â€¢	Crossref/S2: identify app via User-Agent; follow Retry-After.
	â€¢	Deadâ€‘letter queues for persistent 4xx/5xx; alert when DLQ > threshold.

3) Canonicalization & Merge
	â€¢	Canonical ID: doi || normalizedURL(host+path); hash as canonicalId.
	â€¢	Normalization: lowercase host, strip UTM + fragments, drop trailing slash.
	â€¢	Merge rules: Reddit/Substack/YouTube items that reference a DOI/URL do not create new primaries; they become related_refs linked to the canonical item.

4) Selective Enrichment (Cost Control)
	â€¢	Scoring preâ€‘pass (cheap): source authority + recency + basic engagement proxy (channel age, subscriber tier if available, or heuristic).
	â€¢	Transcript fetch only for the top 10â€“20% by score.
	â€¢	LLM summarization only for the top 2â€“5% or when an item is placed in a userâ€™s digest (demandâ€‘driven).
	â€¢	Cache all transcripts and summaries; reuse across users/digests.

5) Chat Architecture
	â€¢	Twoâ€‘stage pipeline: (1) retrieve top N items (or whole digest) â†’ (2) summarizer/synthesizer with strict citeâ€‘only constraints.
	â€¢	Modes: summarize_digest, answer_question, compare_items, debunk (each with tailored prompts).
	â€¢	Guardrails: â€œAnswer only from provided items; if insufficient, ask for more context.â€
	â€¢	Store prompt_version & model_version with outputs for rollback.

6) Storage & Indexing
	â€¢	Indexes: items(published_at DESC), GIN on items.topics, and a tsvector on title + excerpt + summary.
	â€¢	Embeddings: pgvector (ivfflat) for item_embeddings to enable fast semantic search per digest/topic.

7) Observability & Analytics
	â€¢	Logging: pino with requestId/jobId correlation.
	â€¢	Errors: Sentry wired to server + workers.
	â€¢	Health: /healthz and /readiness endpoints.
	â€¢	Metrics (emit counters/gauges):
	â€¢	rss_items_fetched, items_merged, transcripts_ok/failed,
	â€¢	summaries_created, token_spend{userId}, digest_build_time, dlq_depth{queue}.
	â€¢	Product analytics (PostHog or Plausible): wizard_start, topic_select, bundle_add, source_add, digest_created, digest_opened, chat_ask, chat_tokens, stripe_checkout.

8) Email Deliverability
	â€¢	Use Resend/Postmark; configure SPF/DKIM/DMARC (BIMI later).
	â€¢	Start with lightweight HTML + plaintext; warm domain before bulk sends.

9) Compliance & UX
	â€¢	Show source + link and contentâ€‘type badges: Peerâ€‘reviewed / Preprint / Expert Opinion / News.
	â€¢	Display medical disclaimer in digests and chat.

â¸»

ğŸ—‚ï¸ Work Items (Combine Replitâ€™s â€œReady to Implementâ€ + Additions)

From Replitâ€™s â€œReady to Implementâ€
	â€¢	Feed Discovery Service (YouTube RSS, PodcastIndex, Reddit RSS, Substack)
	â€¢	Feed Discovery UI with Search
	â€¢	Onboarding Wizard
	â€¢	Stripe Subscription Flow (Free, Premium, Pro)
	â€¢	Userâ€‘level Digest Generation (weekly/daily)
	â€¢	Enhanced Conversational Chat
	â€¢	Chat History Persistence

Additional Mustâ€‘Haves (Scale & Quality)
	â€¢	BullMQ job queues with perâ€‘source concurrency, backoff, DLQ
	â€¢	Canonical merge (DOI/URL) + related_refs linkage
	â€¢	Selective enrichment pipeline (score â†’ transcript â†’ summarize on demand)
	â€¢	Caching layers: transcripts, summaries, RSS ETag/Lastâ€‘Modified
	â€¢	Indexes (published_at, topics GIN, tsvector) + pgvector for semantic search
	â€¢	Observability: Sentry, pino, /healthz, metrics counters
	â€¢	Product analytics events (activation funnel + token usage)
	â€¢	Email sender (Resend/Postmark) + SPF/DKIM/DMARC
	â€¢	Quality badges (Peerâ€‘reviewed/Preprint/Opinion) + starter bundles (curated sources by topic)
	â€¢	Feature gates & usage caps per tier (chat limits, digest frequency)

â¸»

ğŸ”© Implementation Notes (Concrete Specs)

BullMQ Queues (example config)
	â€¢	Queues: rssFetch, ytTranscript, metadataEnrich, summaryBuild, digestBuild.
	â€¢	Concurrency:
	â€¢	rssFetch: 50
	â€¢	ytTranscript: 8
	â€¢	metadataEnrich: 10
	â€¢	summaryBuild: 6
	â€¢	digestBuild: 4
	â€¢	Retry/backoff: exponential, base 2000ms, factor 2, jitter 0.4, maxRetries 5.
	â€¢	DLQ: *-dlq; alert when depth > 100 or >2% of total jobs in 24h.

Canonicalizer (pseudo)

canonicalUrl = normalize(url) // strip utm/*, lower host, drop #*, normalize path slashes
canonicalId = doi || sha256(canonicalUrl)
if (refersTo(canonicalId)) -> create related_ref; else upsert primary item

Selective Enrichment (pseudo)

score = w1*sourceAuthority + w2*recency + w3*engagementProxy
if score > T1: fetchTranscript(videoId)
if score > T2 or itemInUserDigest: buildSummary(item)
cache(transcript, summary)

Chat Summarizer (digest mode)
	â€¢	Input: ordered list of items + cached summaries.
	â€¢	Prompt guardrails: â€œAnswer only from these items. Cite titles with links. If insufficient, state limitation.â€
	â€¢	Output: sectioned TL;DR + perâ€‘item citations.

â¸»

ğŸ—ºï¸ Rollout Plan (Milestones)
	1.	M1 (Week 1â€‘2): Feed Discovery Service, curated catalog + bundles, Discovery UI, Onboarding Wizard (MVP).
	2.	M2 (Week 3): BullMQ queues + caching + canonical merge; basic observability (Sentry/logs/health).
	3.	M3 (Week 4): Chat twoâ€‘stage summarizer + digest summarize mode; chat history; badges.
	4.	M4 (Week 5): Stripe subscriptions + feature gates; email sender + domain auth; first real user cohort.
	5.	M5 (Week 6): Indexes + pgvector; activation funnel analytics; token usage dashboards; polish.

â¸»

âœ… Test Plan (Smoke + Scale)
	â€¢	Smoke: ingest 100 feeds, build 10 digests, run 20 chat queries (digest summarize & Q&A) â†’ 0 unhandled errors.
	â€¢	Backoff test: force 429s on transcript queue â†’ verify retries, reduced concurrency, DLQ thresholds/alerts.
	â€¢	Canonical test: same DOI from journal + Reddit + Substack â†’ 1 primary item + 2 related_refs.
	â€¢	Cost test: confirm summaries only created on demand and cached; token spend per user recorded.
	â€¢	Load: 10k items/day â†’ queue latency under 5 minutes; API error rate < 2%.

â¸»

ğŸ“ Notes to Replit
	â€¢	Keep ingestion RSSâ€‘first; avoid brittle scraping. Transcript fetching must be polite (UA header, backoff, caching).
	â€¢	All new code behind feature flags for quick rollback.
	â€¢	Ship small, endâ€‘toâ€‘end vertical slices (wizard â†’ add sources â†’ create first digest â†’ chat about it) before broadening.